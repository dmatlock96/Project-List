{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notes\n",
    "* Check the distribution of the target variable of the out of folds score and the prediction distribution. A good model should more or less have the same distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/data-science-bowl-2019/train.csv\n",
      "/kaggle/input/data-science-bowl-2019/specs.csv\n",
      "/kaggle/input/data-science-bowl-2019/train_labels.csv\n",
      "/kaggle/input/data-science-bowl-2019/test.csv\n",
      "/kaggle/input/data-science-bowl-2019/sample_submission.csv\n"
     ]
    }
   ],
   "source": [
    "#result\n",
    "#ver1:LGB、lgb cv mean QWK score : 0.5208321783509067、LB：0.536(+0.015)\n",
    "#ver2:0.8LGB+0.2XGB\n",
    "#lgb cv mean QWK score : 0.5076390431140777、xgb cv mean QWK score : 0.49945107302527625\n",
    "#LB：0.534\n",
    "#ver4:LGB+XGB(LidgeでEnsemble)\n",
    "\n",
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "import matplotlib.pyplot as plt\n",
    "import gc\n",
    "import seaborn as sns\n",
    "import scipy as sp\n",
    "import multiprocessing\n",
    "import scipy as sp\n",
    "import time\n",
    "import random\n",
    "import json\n",
    "\n",
    "from multiprocessing import Lock, Process, Queue, current_process\n",
    "from math import sqrt\n",
    "from numba import jit\n",
    "from functools import partial\n",
    "from tqdm import tqdm as tqdm\n",
    "from collections import Counter\n",
    "from sklearn.metrics import cohen_kappa_score, mean_squared_error\n",
    "from sklearn.metrics import confusion_matrix as sk_cmatrix\n",
    "from sklearn.model_selection import StratifiedKFold, KFold, RepeatedKFold, GroupKFold, GridSearchCV, train_test_split, TimeSeriesSplit, RepeatedStratifiedKFold\n",
    "from catboost import CatBoostRegressor\n",
    "np.random.seed(724)\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "pd.set_option('display.max_columns', 1000)\n",
    "pd.set_option('max_rows', 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data():\n",
    "    start = time.time()\n",
    "    print(\"Start read data\")\n",
    "\n",
    "    train = pd.read_csv('/kaggle/input/data-science-bowl-2019/train.csv')\n",
    "    #train = pd.read_csv('../input/data-science-bowl-2019/train.csv', nrows=1200000)\n",
    "    print('Training.csv file have {} rows and {} columns'.format(train.shape[0], train.shape[1]))\n",
    "\n",
    "    print('Reading test.csv file....')\n",
    "    test = pd.read_csv('/kaggle/input/data-science-bowl-2019/test.csv')\n",
    "    #test = pd.read_csv('../input/data-science-bowl-2019/test.csv', nrows=30000)\n",
    "\n",
    "    print('Test.csv file have {} rows and {} columns'.format(test.shape[0], test.shape[1]))\n",
    "\n",
    "    print('Reading train_labels.csv file....')\n",
    "    train_labels = pd.read_csv('/kaggle/input/data-science-bowl-2019/train_labels.csv')\n",
    "    print('Train_labels.csv file have {} rows and {} columns'.format(train_labels.shape[0], train_labels.shape[1]))\n",
    "\n",
    "    print('Reading specs.csv file....')\n",
    "    specs = pd.read_csv('/kaggle/input/data-science-bowl-2019/specs.csv')\n",
    "    print('Specs.csv file have {} rows and {} columns'.format(specs.shape[0], specs.shape[1]))\n",
    "\n",
    "    print('Reading sample_submission.csv file....')\n",
    "    sample_submission = pd.read_csv('/kaggle/input/data-science-bowl-2019/sample_submission.csv')\n",
    "    print('Sample_submission.csv file have {} rows and {} columns'.format(sample_submission.shape[0], sample_submission.shape[1]))\n",
    "\n",
    "    print(\"read data done, time - \", time.time() - start)\n",
    "    return train, test, train_labels, specs, sample_submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_title(train, test, train_labels):\n",
    "    start = time.time()\n",
    "\n",
    "    print(\"Start encoding data\")\n",
    "    # encode title\n",
    "    train['title_event_code'] = list(map(lambda x, y: str(x) + '_' + str(y), train['title'], train['event_code']))\n",
    "    test['title_event_code'] = list(map(lambda x, y: str(x) + '_' + str(y), test['title'], test['event_code']))\n",
    "    all_title_event_code = list(set(train[\"title_event_code\"].unique()).union(test[\"title_event_code\"].unique()))\n",
    "\n",
    "    train['type_world'] = list(map(lambda x, y: str(x) + '_' + str(y), train['type'], train['world']))\n",
    "    test['type_world'] = list(map(lambda x, y: str(x) + '_' + str(y), test['type'], test['world']))\n",
    "    all_type_world = list(set(train[\"type_world\"].unique()).union(test[\"type_world\"].unique()))\n",
    "\n",
    "    # make a list with all the unique 'titles' from the train and test set\n",
    "    list_of_user_activities = list(set(train['title'].unique()).union(set(test['title'].unique())))\n",
    "    # make a list with all the unique 'event_code' from the train and test set\n",
    "    list_of_event_code = list(set(train['event_code'].unique()).union(set(test['event_code'].unique())))\n",
    "    list_of_event_id = list(set(train['event_id'].unique()).union(set(test['event_id'].unique())))\n",
    "    # make a list with all the unique worlds from the train and test set\n",
    "    list_of_worlds = list(set(train['world'].unique()).union(set(test['world'].unique())))\n",
    "    # create a dictionary numerating the titles\n",
    "    activities_map = dict(zip(list_of_user_activities, np.arange(len(list_of_user_activities))))\n",
    "    activities_labels = dict(zip(np.arange(len(list_of_user_activities)), list_of_user_activities))\n",
    "    activities_world = dict(zip(list_of_worlds, np.arange(len(list_of_worlds))))\n",
    "    assess_titles = list(set(train[train['type'] == 'Assessment']['title'].value_counts().index).union(\n",
    "        set(test[test['type'] == 'Assessment']['title'].value_counts().index)))\n",
    "    # replace the text titles with the number titles from the dict\n",
    "    train['title'] = train['title'].map(activities_map)\n",
    "    test['title'] = test['title'].map(activities_map)\n",
    "    train['world'] = train['world'].map(activities_world)\n",
    "    test['world'] = test['world'].map(activities_world)\n",
    "    train_labels['title'] = train_labels['title'].map(activities_map)\n",
    "    win_code = dict(zip(activities_map.values(), (4100 * np.ones(len(activities_map))).astype('int')))\n",
    "    # then, it set one element, the 'Bird Measurer (Assessment)' as 4110, 10 more than the rest\n",
    "    win_code[activities_map['Bird Measurer (Assessment)']] = 4110\n",
    "    # convert text into datetime\n",
    "    train['timestamp'] = pd.to_datetime(train['timestamp'])\n",
    "    test['timestamp'] = pd.to_datetime(test['timestamp'])\n",
    "    print(\"End encoding data, time - \", time.time() - start)\n",
    "\n",
    "\n",
    "    event_data = {}\n",
    "    event_data[\"train_labels\"] = train_labels\n",
    "    event_data[\"win_code\"] = win_code\n",
    "    event_data[\"list_of_user_activities\"] = list_of_user_activities\n",
    "    event_data[\"list_of_event_code\"] = list_of_event_code\n",
    "    event_data[\"activities_labels\"] = activities_labels\n",
    "    event_data[\"assess_titles\"] = assess_titles\n",
    "    event_data[\"list_of_event_id\"] = list_of_event_id\n",
    "    event_data[\"all_title_event_code\"] = all_title_event_code\n",
    "    event_data[\"activities_map\"] = activities_map\n",
    "    event_data[\"all_type_world\"] = all_type_world\n",
    "\n",
    "    return train, test, event_data\n",
    "def get_all_features(feature_dict, ac_data):\n",
    "    if len(ac_data['durations']) > 0:\n",
    "        feature_dict['installation_duration_mean'] = np.mean(ac_data['durations'])\n",
    "        feature_dict['installation_duration_sum'] = np.sum(ac_data['durations'])\n",
    "    else:\n",
    "        feature_dict['installation_duration_mean'] = 0\n",
    "        feature_dict['installation_duration_sum'] = 0\n",
    "\n",
    "    return feature_dict\n",
    "def get_data(user_sample, event_data, test_set):\n",
    "    '''\n",
    "    The user_sample is a DataFrame from train or test where the only one\n",
    "    installation_id is filtered\n",
    "    And the test_set parameter is related with the labels processing, that is only requered\n",
    "    if test_set=False\n",
    "    '''\n",
    "    # Constants and parameters declaration\n",
    "    last_assesment = {}\n",
    "\n",
    "    last_activity = 0\n",
    "\n",
    "    user_activities_count = {'Clip': 0, 'Activity': 0, 'Assessment': 0, 'Game': 0}\n",
    "\n",
    "    assess_4020_acc_dict = {'Cauldron Filler (Assessment)_4020_accuracy': 0,\n",
    "                            'Mushroom Sorter (Assessment)_4020_accuracy': 0,\n",
    "                            'Bird Measurer (Assessment)_4020_accuracy': 0,\n",
    "                            'Chest Sorter (Assessment)_4020_accuracy': 0}\n",
    "\n",
    "    game_time_dict = {'Clip_gametime': 0, 'Game_gametime': 0,\n",
    "                      'Activity_gametime': 0, 'Assessment_gametime': 0}\n",
    "\n",
    "    last_session_time_sec = 0\n",
    "    accuracy_groups = {0: 0, 1: 0, 2: 0, 3: 0}\n",
    "    all_assessments = []\n",
    "    accumulated_accuracy_group = 0\n",
    "    accumulated_accuracy = 0\n",
    "    accumulated_correct_attempts = 0\n",
    "    accumulated_uncorrect_attempts = 0\n",
    "    accumulated_actions = 0\n",
    "\n",
    "    # Newly added features\n",
    "    accumulated_game_miss = 0\n",
    "    Cauldron_Filler_4025 = 0\n",
    "    mean_game_round = 0\n",
    "    mean_game_duration = 0\n",
    "    mean_game_level = 0\n",
    "    Assessment_mean_event_count = 0\n",
    "    Game_mean_event_count = 0\n",
    "    Activity_mean_event_count = 0\n",
    "    chest_assessment_uncorrect_sum = 0\n",
    "\n",
    "    counter = 0\n",
    "    time_first_activity = float(user_sample['timestamp'].values[0])\n",
    "    durations = []\n",
    "    durations_game = []\n",
    "    durations_activity = []\n",
    "    last_accuracy_title = {'acc_' + title: -1 for title in event_data[\"assess_titles\"]}\n",
    "    last_game_time_title = {'lgt_' + title: 0 for title in event_data[\"assess_titles\"]}\n",
    "    ac_game_time_title = {'agt_' + title: 0 for title in event_data[\"assess_titles\"]}\n",
    "    ac_true_attempts_title = {'ata_' + title: 0 for title in event_data[\"assess_titles\"]}\n",
    "    ac_false_attempts_title = {'afa_' + title: 0 for title in event_data[\"assess_titles\"]}\n",
    "    event_code_count: dict[str, int] = {ev: 0 for ev in event_data[\"list_of_event_code\"]}\n",
    "    event_code_proc_count = {str(ev) + \"_proc\" : 0. for ev in event_data[\"list_of_event_code\"]}\n",
    "    event_id_count: dict[str, int] = {eve: 0 for eve in event_data[\"list_of_event_id\"]}\n",
    "    title_count: dict[str, int] = {eve: 0 for eve in event_data[\"activities_labels\"].values()}\n",
    "    title_event_code_count: dict[str, int] = {t_eve: 0 for t_eve in event_data[\"all_title_event_code\"]}\n",
    "    type_world_count: dict[str, int] = {w_eve: 0 for w_eve in event_data[\"all_type_world\"]}\n",
    "    session_count = 0\n",
    "\n",
    "    # itarates through each session of one instalation_id\n",
    "    for i, session in user_sample.groupby('game_session', sort=False):\n",
    "        # i = game_session_id\n",
    "        # session is a DataFrame that contain only one game_session\n",
    "        # get some sessions information\n",
    "        session_type = session['type'].iloc[0]\n",
    "        session_title = session['title'].iloc[0]\n",
    "        session_title_text = event_data[\"activities_labels\"][session_title]\n",
    "\n",
    "        if session_type == \"Activity\":\n",
    "            Activity_mean_event_count = (Activity_mean_event_count + session['event_count'].iloc[-1]) / 2.0\n",
    "\n",
    "        if session_type == \"Game\":\n",
    "            Game_mean_event_count = (Game_mean_event_count + session['event_count'].iloc[-1]) / 2.0\n",
    "\n",
    "            game_s = session[session.event_code == 2030]\n",
    "            misses_cnt = cnt_miss(game_s)\n",
    "            accumulated_game_miss += misses_cnt\n",
    "\n",
    "            try:\n",
    "                game_round = json.loads(session['event_data'].iloc[-1])[\"round\"]\n",
    "                mean_game_round = (mean_game_round + game_round) / 2.0\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "            try:\n",
    "                game_duration = json.loads(session['event_data'].iloc[-1])[\"duration\"]\n",
    "                mean_game_duration = (mean_game_duration + game_duration) / 2.0\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "            try:\n",
    "                game_level = json.loads(session['event_data'].iloc[-1])[\"level\"]\n",
    "                mean_game_level = (mean_game_level + game_level) / 2.0\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "        # for each assessment, and only this kind off session, the features below are processed\n",
    "        # and a register are generated\n",
    "        if (session_type == 'Assessment') & (test_set or len(session) > 1):\n",
    "            # search for event_code 4100, that represents the assessments trial\n",
    "            all_attempts = session.query(f'event_code == {event_data[\"win_code\"][session_title]}')\n",
    "            # then, check the numbers of wins and the number of losses\n",
    "            true_attempts = all_attempts['event_data'].str.contains('true').sum()\n",
    "            false_attempts = all_attempts['event_data'].str.contains('false').sum()\n",
    "            # copy a dict to use as feature template, it's initialized with some itens:\n",
    "            # {'Clip':0, 'Activity': 0, 'Assessment': 0, 'Game':0}\n",
    "            features = user_activities_count.copy()\n",
    "            features.update(last_accuracy_title.copy())\n",
    "            features.update(event_code_count.copy())\n",
    "            features.update(title_count.copy())\n",
    "            features.update(game_time_dict.copy())\n",
    "            features.update(event_id_count.copy())\n",
    "            features.update(title_event_code_count.copy())\n",
    "            features.update(assess_4020_acc_dict.copy())\n",
    "            features.update(type_world_count.copy())\n",
    "            features.update(last_game_time_title.copy())\n",
    "            features.update(ac_game_time_title.copy())\n",
    "            features.update(ac_true_attempts_title.copy())\n",
    "            features.update(ac_false_attempts_title.copy())\n",
    "\n",
    "            features.update(event_code_proc_count.copy())\n",
    "            features['installation_session_count'] = session_count\n",
    "            features['accumulated_game_miss'] = accumulated_game_miss\n",
    "            features['mean_game_round'] = mean_game_round\n",
    "            features['mean_game_duration'] = mean_game_duration\n",
    "            features['mean_game_level'] = mean_game_level\n",
    "            features['Assessment_mean_event_count'] = Assessment_mean_event_count\n",
    "            features['Game_mean_event_count'] = Game_mean_event_count\n",
    "            features['Activity_mean_event_count'] = Activity_mean_event_count\n",
    "            features['chest_assessment_uncorrect_sum'] = chest_assessment_uncorrect_sum\n",
    "\n",
    "            variety_features = [('var_event_code', event_code_count),\n",
    "                                ('var_event_id', event_id_count),\n",
    "                                ('var_title', title_count),\n",
    "                                ('var_title_event_code', title_event_code_count),\n",
    "                                ('var_type_world', type_world_count)]\n",
    "\n",
    "            for name, dict_counts in variety_features:\n",
    "                arr = np.array(list(dict_counts.values()))\n",
    "                features[name] = np.count_nonzero(arr)\n",
    "\n",
    "            # get installation_id for aggregated features\n",
    "            features['installation_id'] = session['installation_id'].iloc[-1]\n",
    "            # add title as feature, remembering that title represents the name of the game\n",
    "            features['session_title'] = session['title'].iloc[0]\n",
    "            # the 4 lines below add the feature of the history of the trials of this player\n",
    "            # this is based on the all time attempts so far, at the moment of this assessment\n",
    "            features['accumulated_correct_attempts'] = accumulated_correct_attempts\n",
    "            features['accumulated_uncorrect_attempts'] = accumulated_uncorrect_attempts\n",
    "            accumulated_correct_attempts += true_attempts\n",
    "            accumulated_uncorrect_attempts += false_attempts\n",
    "\n",
    "            # ----------------------------------------------\n",
    "            ac_true_attempts_title['ata_' + session_title_text] += true_attempts\n",
    "            ac_false_attempts_title['afa_' + session_title_text] += false_attempts\n",
    "\n",
    "            last_game_time_title['lgt_' + session_title_text] = session['game_time'].iloc[-1]\n",
    "            ac_game_time_title['agt_' + session_title_text] += session['game_time'].iloc[-1]\n",
    "            # ----------------------------------------------\n",
    "\n",
    "            # the time spent in the app so far\n",
    "            if durations == []:\n",
    "                features['duration_mean'] = 0\n",
    "                features['duration_std'] = 0\n",
    "                features['last_duration'] = 0\n",
    "                features['duration_max'] = 0\n",
    "            else:\n",
    "                features['duration_mean'] = np.mean(durations)\n",
    "                features['duration_std'] = np.std(durations)\n",
    "                features['last_duration'] = durations[-1]\n",
    "                features['duration_max'] = np.max(durations)\n",
    "            durations.append((session.iloc[-1, 2] - session.iloc[0, 2]).seconds)\n",
    "\n",
    "            if durations_game == []:\n",
    "                features['duration_game_mean'] = 0\n",
    "                features['duration_game_std'] = 0\n",
    "                features['game_last_duration'] = 0\n",
    "                features['game_max_duration'] = 0\n",
    "            else:\n",
    "                features['duration_game_mean'] = np.mean(durations_game)\n",
    "                features['duration_game_std'] = np.std(durations_game)\n",
    "                features['game_last_duration'] = durations_game[-1]\n",
    "                features['game_max_duration'] = np.max(durations_game)\n",
    "\n",
    "            if durations_activity == []:\n",
    "                features['duration_activity_mean'] = 0\n",
    "                features['duration_activity_std'] = 0\n",
    "                features['game_activity_duration'] = 0\n",
    "                features['game_activity_max'] = 0\n",
    "            else:\n",
    "                features['duration_activity_mean'] = np.mean(durations_activity)\n",
    "                features['duration_activity_std'] = np.std(durations_activity)\n",
    "                features['game_activity_duration'] = durations_activity[-1]\n",
    "                features['game_activity_max'] = np.max(durations_activity)\n",
    "\n",
    "            # the accuracy is the all time wins divided by the all time attempts\n",
    "            features['accumulated_accuracy'] = accumulated_accuracy / counter if counter > 0 else 0\n",
    "            # --------------------------\n",
    "            features['Cauldron_Filler_4025'] = Cauldron_Filler_4025 / counter if counter > 0 else 0\n",
    "\n",
    "            Assess_4025 = session[(session.event_code == 4025) & (session.title == 'Cauldron Filler (Assessment)')]\n",
    "            true_attempts_ = Assess_4025['event_data'].str.contains('true').sum()\n",
    "            false_attempts_ = Assess_4025['event_data'].str.contains('false').sum()\n",
    "\n",
    "            cau_assess_accuracy_ = true_attempts_ / (true_attempts_ + false_attempts_) if (\n",
    "                                                                                                      true_attempts_ + false_attempts_) != 0 else 0\n",
    "            Cauldron_Filler_4025 += cau_assess_accuracy_\n",
    "\n",
    "            chest_assessment_uncorrect_sum += len(session[session.event_id == \"df4fe8b6\"])\n",
    "\n",
    "            Assessment_mean_event_count = (Assessment_mean_event_count + session['event_count'].iloc[-1]) / 2.0\n",
    "            # ----------------------------\n",
    "            accuracy = true_attempts / (true_attempts + false_attempts) if (true_attempts + false_attempts) != 0 else 0\n",
    "            accumulated_accuracy += accuracy\n",
    "            last_accuracy_title['acc_' + session_title_text] = accuracy\n",
    "            # a feature of the current accuracy categorized\n",
    "            # it is a counter of how many times this player was in each accuracy group\n",
    "            if accuracy == 0:\n",
    "                features['accuracy_group'] = 0\n",
    "            elif accuracy == 1:\n",
    "                features['accuracy_group'] = 3\n",
    "            elif accuracy == 0.5:\n",
    "                features['accuracy_group'] = 2\n",
    "            else:\n",
    "                features['accuracy_group'] = 1\n",
    "            features.update(accuracy_groups)\n",
    "            accuracy_groups[features['accuracy_group']] += 1\n",
    "            # mean of the all accuracy groups of this player\n",
    "            features['accumulated_accuracy_group'] = accumulated_accuracy_group / counter if counter > 0 else 0\n",
    "            accumulated_accuracy_group += features['accuracy_group']\n",
    "            # how many actions the player has done so far, it is initialized as 0 and updated some lines below\n",
    "            features['accumulated_actions'] = accumulated_actions\n",
    "\n",
    "            # there are some conditions to allow this features to be inserted in the datasets\n",
    "            # if it's a test set, all sessions belong to the final dataset\n",
    "            # it it's a train, needs to be passed throught this clausule: session.query(f'event_code == {win_code[session_title]}')\n",
    "            # that means, must exist an event_code 4100 or 4110\n",
    "            if test_set:\n",
    "                last_assesment = features.copy()\n",
    "\n",
    "            if true_attempts + false_attempts > 0:\n",
    "                all_assessments.append(features)\n",
    "\n",
    "            counter += 1\n",
    "\n",
    "        if session_type == 'Game':\n",
    "            durations_game.append((session.iloc[-1, 2] - session.iloc[0, 2]).seconds)\n",
    "\n",
    "        if session_type == 'Activity':\n",
    "            durations_activity.append((session.iloc[-1, 2] - session.iloc[0, 2]).seconds)\n",
    "\n",
    "        session_count += 1\n",
    "\n",
    "        # this piece counts how many actions was made in each event_code so far\n",
    "        def update_counters(counter: dict, col: str):\n",
    "            num_of_session_count = Counter(session[col])\n",
    "            for k in num_of_session_count.keys():\n",
    "                x = k\n",
    "                if col == 'title':\n",
    "                    x = event_data[\"activities_labels\"][k]\n",
    "                counter[x] += num_of_session_count[k]\n",
    "            return counter\n",
    "\n",
    "        def update_proc(count: dict):\n",
    "            res = {}\n",
    "            for k, val in count.items():\n",
    "                res[str(k) + \"_proc\"] = (float(val) * 100.0) / accumulated_actions\n",
    "            return res\n",
    "\n",
    "        event_code_count = update_counters(event_code_count, \"event_code\")\n",
    "\n",
    "\n",
    "        event_id_count = update_counters(event_id_count, \"event_id\")\n",
    "        title_count = update_counters(title_count, 'title')\n",
    "        title_event_code_count = update_counters(title_event_code_count, 'title_event_code')\n",
    "        type_world_count = update_counters(type_world_count, 'type_world')\n",
    "\n",
    "        assess_4020_acc_dict = get_4020_acc(session, assess_4020_acc_dict, event_data)\n",
    "        game_time_dict[session_type + '_gametime'] = (game_time_dict[session_type + '_gametime'] + (\n",
    "                    session['game_time'].iloc[-1] / 1000.0)) / 2.0\n",
    "\n",
    "        # counts how many actions the player has done so far, used in the feature of the same name\n",
    "        accumulated_actions += len(session)\n",
    "        event_code_proc_count = update_proc(event_code_count)\n",
    "\n",
    "        if last_activity != session_type:\n",
    "            user_activities_count[session_type] += 1\n",
    "            last_activitiy = session_type\n",
    "\n",
    "            # if it't the test_set, only the last assessment must be predicted, the previous are scraped\n",
    "    if test_set:\n",
    "        return last_assesment, all_assessments\n",
    "    # in the train_set, all assessments goes to the dataset\n",
    "    return all_assessments\n",
    "\n",
    "def cnt_miss(df):\n",
    "    cnt = 0\n",
    "    for e in range(len(df)):\n",
    "        x = df['event_data'].iloc[e]\n",
    "        y = json.loads(x)['misses']\n",
    "        cnt += y\n",
    "    return cnt\n",
    "\n",
    "def get_4020_acc(df, counter_dict, event_data):\n",
    "    for e in ['Cauldron Filler (Assessment)', 'Bird Measurer (Assessment)',\n",
    "              'Mushroom Sorter (Assessment)', 'Chest Sorter (Assessment)']:\n",
    "        Assess_4020 = df[(df.event_code == 4020) & (df.title == event_data[\"activities_map\"][e])]\n",
    "        true_attempts_ = Assess_4020['event_data'].str.contains('true').sum()\n",
    "        false_attempts_ = Assess_4020['event_data'].str.contains('false').sum()\n",
    "\n",
    "        measure_assess_accuracy_ = true_attempts_ / (true_attempts_ + false_attempts_) if (\n",
    "                                                                                                      true_attempts_ + false_attempts_) != 0 else 0\n",
    "        counter_dict[e + \"_4020_accuracy\"] += (counter_dict[e + \"_4020_accuracy\"] + measure_assess_accuracy_) / 2.0\n",
    "\n",
    "    return counter_dict\n",
    "\n",
    "def get_users_data(users_list, return_dict,  event_data, test_set):\n",
    "    if test_set:\n",
    "        for user in users_list:\n",
    "            return_dict.append(get_data(user, event_data, test_set))\n",
    "    else:\n",
    "        answer = []\n",
    "        for user in users_list:\n",
    "            answer += get_data(user, event_data, test_set)\n",
    "        return_dict += answer\n",
    "\n",
    "def get_data_parrallel(users_list, event_data, test_set):\n",
    "    manager = multiprocessing.Manager()\n",
    "    return_dict = manager.list()\n",
    "    threads_number = event_data[\"process_numbers\"]\n",
    "    data_len = len(users_list)\n",
    "    processes = []\n",
    "    cur_start = 0\n",
    "    cur_stop = 0\n",
    "    for index in range(threads_number):\n",
    "        cur_stop += (data_len-1) // threads_number\n",
    "\n",
    "        if index != (threads_number - 1):\n",
    "            p = Process(target=get_users_data, args=(users_list[cur_start:cur_stop], return_dict, event_data, test_set))\n",
    "        else:\n",
    "            p = Process(target=get_users_data, args=(users_list[cur_start:], return_dict, event_data, test_set))\n",
    "\n",
    "        processes.append(p)\n",
    "        cur_start = cur_stop\n",
    "\n",
    "    for proc in processes:\n",
    "        proc.start()\n",
    "\n",
    "    for proc in processes:\n",
    "        proc.join()\n",
    "\n",
    "    return list(return_dict)\n",
    "\n",
    "def get_train_and_test(train, test, event_data):\n",
    "    start = time.time()\n",
    "    print(\"Start get_train_and_test\")\n",
    "\n",
    "    compiled_train = []\n",
    "    compiled_test = []\n",
    "\n",
    "    user_train_list = []\n",
    "    user_test_list = []\n",
    "\n",
    "    stride_size = event_data[\"strides\"]\n",
    "    for i, (ins_id, user_sample) in tqdm(enumerate(train.groupby('installation_id', sort=False)), total=17000):\n",
    "        user_train_list.append(user_sample)\n",
    "        if (i + 1) % stride_size == 0:\n",
    "            compiled_train += get_data_parrallel(user_train_list, event_data, False)\n",
    "            del user_train_list\n",
    "            user_train_list = []\n",
    "\n",
    "    if len(user_train_list) > 0:\n",
    "        compiled_train += get_data_parrallel(user_train_list, event_data, False)\n",
    "        del user_train_list\n",
    "\n",
    "    for i, (ins_id, user_sample) in tqdm(enumerate(test.groupby('installation_id', sort=False)), total=1000):\n",
    "        user_test_list.append(user_sample)\n",
    "        if (i + 1) % stride_size == 0:\n",
    "            compiled_test += get_data_parrallel(user_test_list, event_data, True)\n",
    "            del user_test_list\n",
    "            user_test_list = []\n",
    "\n",
    "    if len(user_test_list) > 0:\n",
    "        compiled_test += get_data_parrallel(user_test_list, event_data, True)\n",
    "        del user_test_list\n",
    "\n",
    "    reduce_train = pd.DataFrame(compiled_train)\n",
    "\n",
    "    reduce_test = [x[0] for x in compiled_test]\n",
    "\n",
    "    reduce_train_from_test = []\n",
    "    for i in [x[1] for x in compiled_test]:\n",
    "        reduce_train_from_test += i\n",
    "\n",
    "    reduce_test = pd.DataFrame(reduce_test)\n",
    "    reduce_train_from_test = pd.DataFrame(reduce_train_from_test)\n",
    "    print(\"End get_train_and_test, time - \", time.time() - start)\n",
    "    return reduce_train, reduce_test, reduce_train_from_test\n",
    "\n",
    "def get_train_and_test_single_proc(train, test, event_data):\n",
    "    compiled_train = []\n",
    "    compiled_test = []\n",
    "    compiled_test_his = []\n",
    "    for ins_id, user_sample in tqdm(train.groupby('installation_id', sort=False), total=17000):\n",
    "        compiled_train += get_data(user_sample, event_data, False)\n",
    "    for ins_id, user_sample in tqdm(test.groupby('installation_id', sort=False), total=1000):\n",
    "        test_data = get_data(user_sample, event_data, True)\n",
    "        compiled_test.append(test_data[0])\n",
    "        compiled_test_his += test_data[1]\n",
    "\n",
    "\n",
    "    reduce_train = pd.DataFrame(compiled_train)\n",
    "    reduce_test = pd.DataFrame(compiled_test)\n",
    "    reduce_test_his = pd.DataFrame(compiled_test_his)\n",
    "\n",
    "    return reduce_train, reduce_test, reduce_test_his"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_qwk_lgb_regr(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Fast cappa eval function for lgb.\n",
    "    \"\"\"\n",
    "    dist = Counter(reduce_train['accuracy_group'])\n",
    "    for k in dist:\n",
    "        dist[k] /= len(reduce_train)\n",
    "    reduce_train['accuracy_group'].hist()\n",
    "    \n",
    "    acum = 0\n",
    "    bound = {}\n",
    "    for i in range(3):\n",
    "        acum += dist[i]\n",
    "        bound[i] = np.percentile(y_pred, acum * 100)\n",
    "\n",
    "    def classify(x):\n",
    "        if x <= bound[0]:\n",
    "            return 0\n",
    "        elif x <= bound[1]:\n",
    "            return 1\n",
    "        elif x <= bound[2]:\n",
    "            return 2\n",
    "        else:\n",
    "            return 3\n",
    "\n",
    "    y_pred = np.array(list(map(classify, y_pred))).reshape(y_true.shape)\n",
    "\n",
    "    return 'cappa', cohen_kappa_score(y_true, y_pred, weights='quadratic'), True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cohenkappa(ypred, y):\n",
    "    y = y.get_label().astype(\"int\")\n",
    "    ypred = ypred.reshape((4, -1)).argmax(axis = 0)\n",
    "    loss = cohenkappascore(y, y_pred, weights = 'quadratic')\n",
    "    return \"cappa\", loss, True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Base_Model(object):\n",
    "    \n",
    "    def __init__(self, train_df, test_df, features, categoricals=[], n_splits=5, verbose=True):\n",
    "        self.train_df = train_df\n",
    "        self.test_df = test_df\n",
    "        self.features = features\n",
    "        self.n_splits = n_splits\n",
    "        self.categoricals = categoricals\n",
    "        self.target = 'accuracy_group'\n",
    "        self.cv = self.get_cv()\n",
    "        self.verbose = verbose\n",
    "        self.params = self.get_params()\n",
    "        self.y_pred, self.score, self.model = self.fit()\n",
    "        \n",
    "    def train_model(self, train_set, val_set):\n",
    "        raise NotImplementedError\n",
    "        \n",
    "    def get_cv(self):\n",
    "        cv = StratifiedKFold(n_splits=self.n_splits, shuffle=True, random_state=42)\n",
    "        return cv.split(self.train_df, self.train_df[self.target])\n",
    "    \n",
    "    def get_params(self):\n",
    "        raise NotImplementedError\n",
    "        \n",
    "    def convert_dataset(self, x_train, y_train, x_val, y_val):\n",
    "        raise NotImplementedError\n",
    "        \n",
    "    def convert_x(self, x):\n",
    "        return x\n",
    "        \n",
    "    def fit(self):\n",
    "        oof_pred = np.zeros((len(reduce_train), ))\n",
    "        y_pred = np.zeros((len(reduce_test), ))\n",
    "        for fold, (train_idx, val_idx) in enumerate(self.cv):\n",
    "            x_train, x_val = self.train_df[self.features].iloc[train_idx], self.train_df[self.features].iloc[val_idx]\n",
    "            y_train, y_val = self.train_df[self.target][train_idx], self.train_df[self.target][val_idx]\n",
    "            train_set, val_set = self.convert_dataset(x_train, y_train, x_val, y_val)\n",
    "            model = self.train_model(train_set, val_set)\n",
    "            conv_x_val = self.convert_x(x_val)\n",
    "            oof_pred[val_idx] = model.predict(conv_x_val).reshape(oof_pred[val_idx].shape)\n",
    "            x_test = self.convert_x(self.test_df[self.features])\n",
    "            y_pred += model.predict(x_test).reshape(y_pred.shape) / self.n_splits\n",
    "            print('Partial score of fold {} is: {}'.format(fold, eval_qwk_lgb_regr(y_val, oof_pred[val_idx])[1]))\n",
    "        _, loss_score, _ = eval_qwk_lgb_regr(self.train_df[self.target], oof_pred)\n",
    "        if self.verbose:\n",
    "            print('Our oof cohen kappa score is: ', loss_score)\n",
    "        return y_pred, loss_score, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Lgb_Model(Base_Model):\n",
    "    \n",
    "    def train_model(self, train_set, val_set):\n",
    "        verbosity = 100 if self.verbose else 0\n",
    "        return lgb.train(self.params, train_set, valid_sets=[train_set, val_set], verbose_eval=verbosity)\n",
    "        \n",
    "    def convert_dataset(self, x_train, y_train, x_val, y_val):\n",
    "        train_set = lgb.Dataset(x_train, y_train, categorical_feature=self.categoricals)\n",
    "        val_set = lgb.Dataset(x_val, y_val, categorical_feature=self.categoricals)\n",
    "        return train_set, val_set\n",
    "        \n",
    "    def get_params(self):\n",
    "        params = {'n_estimators':5000,\n",
    "                    'boosting_type': 'gbdt',\n",
    "                    'objective': 'regression',\n",
    "                    'metric': 'rmse',\n",
    "                    'subsample': 0.75,\n",
    "                    'subsample_freq': 1,\n",
    "                    'learning_rate': 0.01,\n",
    "                    'feature_fraction': 0.9,\n",
    "                    'max_depth': 15,\n",
    "                    'lambda_l1': 1,  \n",
    "                    'lambda_l2': 1,\n",
    "                    'early_stopping_rounds': 100\n",
    "                    }\n",
    "        return params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Xgb_Model(Base_Model):\n",
    "    \n",
    "    def train_model(self, train_set, val_set):\n",
    "        verbosity = 100 if self.verbose else 0\n",
    "        return xgb.train(self.params, train_set, \n",
    "                         num_boost_round=5000, evals=[(train_set, 'train'), (val_set, 'val')], \n",
    "                         verbose_eval=verbosity, early_stopping_rounds=100)\n",
    "        \n",
    "    def convert_dataset(self, x_train, y_train, x_val, y_val):\n",
    "        train_set = xgb.DMatrix(x_train, y_train)\n",
    "        val_set = xgb.DMatrix(x_val, y_val)\n",
    "        return train_set, val_set\n",
    "    \n",
    "    def convert_x(self, x):\n",
    "        return xgb.DMatrix(x)\n",
    "        \n",
    "    def get_params(self):\n",
    "        params = {'colsample_bytree': 0.8,                 \n",
    "            'learning_rate': 0.01,\n",
    "            'max_depth': 10,\n",
    "            'subsample': 1,\n",
    "            'objective':'reg:squarederror',\n",
    "            #'eval_metric':'rmse',\n",
    "            'min_child_weight':3,\n",
    "            'gamma':0.25,\n",
    "            'n_estimators':5000}\n",
    "\n",
    "        return params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_kaggle = True\n",
    "#random.seed(42)\n",
    "start_program = time.time()\n",
    "\n",
    "event_data = {}\n",
    "if in_kaggle:\n",
    "    event_data[\"strides\"] = 300\n",
    "    event_data[\"process_numbers\"] = 4\n",
    "else:\n",
    "    event_data[\"strides\"] = 300\n",
    "    event_data[\"process_numbers\"] = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start read data\n",
      "Training.csv file have 11341042 rows and 11 columns\n",
      "Reading test.csv file....\n",
      "Test.csv file have 1156414 rows and 11 columns\n",
      "Reading train_labels.csv file....\n",
      "Train_labels.csv file have 17690 rows and 7 columns\n",
      "Reading specs.csv file....\n",
      "Specs.csv file have 386 rows and 3 columns\n",
      "Reading sample_submission.csv file....\n",
      "Sample_submission.csv file have 1000 rows and 2 columns\n",
      "read data done, time -  85.69977593421936\n",
      "Start encoding data\n",
      "End encoding data, time -  72.43243908882141\n",
      "Start get_train_and_test\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 17000/17000 [30:54<00:00,  9.17it/s]\n",
      "100%|██████████| 1000/1000 [02:44<00:00,  6.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End get_train_and_test, time -  2070.994749069214\n"
     ]
    }
   ],
   "source": [
    "# read data\n",
    "train, test, train_labels, specs, sample_submission = read_data()\n",
    "# get usefull dict with maping encode\n",
    "train, test, event_data_update = encode_title(train, test, train_labels)\n",
    "event_data.update(event_data_update)\n",
    "\n",
    "#reduce_train, reduce_test, reduce_train_from_test = get_train_and_test_single_proc(train, test, event_data)\n",
    "reduce_train, reduce_test, reduce_train_from_test = get_train_and_test(train, test, event_data)\n",
    "\n",
    "categoricals = ['session_title']\n",
    "\n",
    "dels = [train, test]\n",
    "del dels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduce_train.sort_values(\"installation_id\", axis=0, ascending=True, inplace=True, na_position='last')\n",
    "reduce_test.sort_values(\"installation_id\", axis=0, ascending=True, inplace=True, na_position='last')\n",
    "reduce_train = pd.concat([reduce_train, reduce_train_from_test], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stract_hists(feature, train=reduce_train, test=reduce_test, adjust=False, plot=False):\n",
    "    n_bins = 10\n",
    "    train_data = train[feature]\n",
    "    test_data = test[feature]\n",
    "    if adjust:\n",
    "        test_data *= train_data.mean() / test_data.mean()\n",
    "    perc_90 = np.percentile(train_data, 95)\n",
    "    train_data = np.clip(train_data, 0, perc_90)\n",
    "    test_data = np.clip(test_data, 0, perc_90)\n",
    "    train_hist = np.histogram(train_data, bins=n_bins)[0] / len(train_data)\n",
    "    test_hist = np.histogram(test_data, bins=n_bins)[0] / len(test_data)\n",
    "    msre = mean_squared_error(train_hist, test_hist)\n",
    "    if plot:\n",
    "        print(msre)\n",
    "        plt.bar(range(n_bins), train_hist, color='blue', alpha=0.5)\n",
    "        plt.bar(range(n_bins), test_hist, color='red', alpha=0.5)\n",
    "        plt.show()\n",
    "    return msre\n",
    "#stract_hists('Magma Peak - Level 1_2000', adjust=False, plot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# call feature engineering function\n",
    "features = reduce_train.loc[(reduce_train.sum(axis=1) != 0), (reduce_train.sum(axis=0) != 0)].columns # delete useless columns\n",
    "features = [x for x in features if x not in ['accuracy_group', 'installation_id']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = 0\n",
    "to_remove = []\n",
    "# for feat_a in features:\n",
    "#     for feat_b in features:\n",
    "#         if feat_a != feat_b and feat_a not in to_remove and feat_b not in to_remove:\n",
    "#             c = np.corrcoef(reduce_train[feat_a], reduce_train[feat_b])[0][1]\n",
    "#             if c > 0.995:\n",
    "#                 counter += 1\n",
    "#                 to_remove.append(feat_b)\n",
    "#                 print('{}: FEAT_A: {} FEAT_B: {} - Correlation: {}'.format(counter, feat_a, feat_b, c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clip_gametime 0.0 0.0\n",
      "13f56524 0.03942561396387254 0.0\n",
      "eb2c19cd 0.1565354170895068 0.008 0.0\n",
      "0ce40006 0.000761112238684798 0.0\n",
      "4074bac2 0.0 0.0\n",
      "e4d32835 0.001167038765983357 0.0\n",
      "611485c5 0.0012177795818956768 0.0\n",
      "6aeafed4 0.13415871727217374 0.008 0.0\n",
      "17ca3959 0.0 0.0\n",
      "2ec694de 0.00806778973005886 0.0\n",
      "dcb1663e 0.0 0.0\n",
      "a8cc6fec 0.0 0.0\n",
      "003cd2ee 0.0 0.0\n",
      "bfc77bd6 0.01151816521209661 0.0\n",
      "1b54d27f 0.0006596306068601583 0.0\n",
      "5dc079d8 0.0 0.0\n",
      "ecc6157f 0.006545565252689263 0.0\n",
      "7fd1ac25 0.017759285569311955 0.0\n",
      "ab4ec3a4 0.0008118530545971179 0.0\n",
      "119b5b02 0.00025370407956159933 0.0\n",
      "01ca3a3c 0.00040592652729855896 0.0\n",
      "29a42aea 0.0036533387456870307 0.0\n",
      "Cart Balancer (Assessment)_4080 0.006545565252689263 0.0\n",
      "Mushroom Sorter (Assessment)_4080 0.03942561396387254 0.0\n",
      "Air Show_4080 0.0 0.0\n",
      "Dino Drink_4080 0.0008118530545971179 0.0\n",
      "Chest Sorter (Assessment)_4080 0.01151816521209661 0.0\n",
      "Bubble Bath_4090 0.13415871727217374 0.008 0.0\n",
      "Sandcastle Builder (Activity)_2010 0.0 0.0\n",
      "Pan Balance_4080 0.001167038765983357 0.0\n",
      "Leaf Leader_4080 0.00040592652729855896 0.0\n",
      "Mushroom Sorter (Assessment)_4090 0.1565354170895068 0.008 0.0\n",
      "Scrub-A-Dub_4080 0.0 0.0\n",
      "Bug Measurer (Activity)_4080 0.00806778973005886 0.0\n",
      "Egg Dropper (Activity)_4080 0.017759285569311955 0.0\n",
      "Pan Balance_2010 0.0 0.0\n",
      "Fireworks (Activity)_4080 0.0012177795818956768 0.0\n",
      "Crystals Rule_2010 0.0 0.0\n",
      "Bottle Filler (Activity)_2010 0.0 0.0\n",
      "Happy Camel_4080 0.000761112238684798 0.0\n",
      "Watering Hole (Activity)_2010 0.0006596306068601583 0.0\n",
      "Bubble Bath_4080 0.0036533387456870307 0.0\n",
      "Dino Dive_4080 0.00025370407956159933 0.0\n",
      "Cauldron Filler (Assessment)_4020_accuracy 2.067840057107261e+210 5.080517549278432e+102 0.010619428971660901\n",
      "Mushroom Sorter (Assessment)_4020_accuracy 3.3042620617843543e+215 2.1682950808824264e+77 0.00936606996425054\n",
      "Bird Measurer (Assessment)_4020_accuracy 4.3512814405981355e+214 1.1047334545798042e+28 0.0012327833062035943\n",
      "Chest Sorter (Assessment)_4020_accuracy 4.968419902839792e+211 5.156518164058864e+99 0.001664119565349661\n",
      "Cauldron_Filler_4025 0.0 0.0\n"
     ]
    }
   ],
   "source": [
    "to_exclude = [] \n",
    "ajusted_test = reduce_test.copy()\n",
    "for feature in ajusted_test.columns:\n",
    "    if feature not in ['accuracy_group', 'installation_id', 'accuracy_group', 'session_title']:\n",
    "        data = reduce_train[feature]\n",
    "        train_mean = data.mean()\n",
    "        data = ajusted_test[feature] \n",
    "        test_mean = data.mean()\n",
    "        try:\n",
    "            error = stract_hists(feature, adjust=True)\n",
    "            ajust_factor = train_mean / test_mean\n",
    "            if ajust_factor > 10 or ajust_factor < 0.1:# or error > 0.01:\n",
    "                to_exclude.append(feature)\n",
    "                print(feature, train_mean, test_mean, error)\n",
    "            else:\n",
    "                ajusted_test[feature] *= ajust_factor\n",
    "        except:\n",
    "            to_exclude.append(feature)\n",
    "            print(feature, train_mean, test_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19708, 954)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = [x for x in features if x not in (to_exclude + to_remove)]\n",
    "reduce_train[features].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduce_train.columns = [\"\".join (c if c.isalnum() else \"_\" for c in str(x)) for x in reduce_train.columns]\n",
    "ajusted_test.columns = [\"\".join (c if c.isalnum() else \"_\" for c in str(x)) for x in ajusted_test.columns]\n",
    "features = [\"\".join (c if c.isalnum() else \"_\" for c in str(x)) for x in features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 1.02948\tvalid_1's rmse: 1.0486\n",
      "[200]\ttraining's rmse: 0.961598\tvalid_1's rmse: 0.99977\n",
      "[300]\ttraining's rmse: 0.927683\tvalid_1's rmse: 0.985215\n",
      "[400]\ttraining's rmse: 0.903739\tvalid_1's rmse: 0.979783\n",
      "[500]\ttraining's rmse: 0.884194\tvalid_1's rmse: 0.97793\n",
      "[600]\ttraining's rmse: 0.866978\tvalid_1's rmse: 0.977011\n",
      "[700]\ttraining's rmse: 0.851358\tvalid_1's rmse: 0.976434\n",
      "[800]\ttraining's rmse: 0.836748\tvalid_1's rmse: 0.975997\n",
      "[900]\ttraining's rmse: 0.823096\tvalid_1's rmse: 0.975975\n",
      "Early stopping, best iteration is:\n",
      "[856]\ttraining's rmse: 0.828936\tvalid_1's rmse: 0.975891\n",
      "Partial score of fold 0 is: 0.6052837111052434\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 1.02995\tvalid_1's rmse: 1.0482\n",
      "[200]\ttraining's rmse: 0.960826\tvalid_1's rmse: 0.999037\n",
      "[300]\ttraining's rmse: 0.92741\tvalid_1's rmse: 0.984728\n",
      "[400]\ttraining's rmse: 0.90383\tvalid_1's rmse: 0.978595\n",
      "[500]\ttraining's rmse: 0.884388\tvalid_1's rmse: 0.974887\n",
      "[600]\ttraining's rmse: 0.867389\tvalid_1's rmse: 0.972879\n",
      "[700]\ttraining's rmse: 0.85178\tvalid_1's rmse: 0.971829\n",
      "[800]\ttraining's rmse: 0.837495\tvalid_1's rmse: 0.970781\n",
      "[900]\ttraining's rmse: 0.823887\tvalid_1's rmse: 0.970081\n",
      "[1000]\ttraining's rmse: 0.811023\tvalid_1's rmse: 0.969849\n",
      "[1100]\ttraining's rmse: 0.798522\tvalid_1's rmse: 0.969437\n",
      "[1200]\ttraining's rmse: 0.786875\tvalid_1's rmse: 0.969308\n",
      "Early stopping, best iteration is:\n",
      "[1162]\ttraining's rmse: 0.791152\tvalid_1's rmse: 0.969237\n",
      "Partial score of fold 1 is: 0.6048241576136991\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 1.028\tvalid_1's rmse: 1.05043\n",
      "[200]\ttraining's rmse: 0.959991\tvalid_1's rmse: 1.00332\n",
      "[300]\ttraining's rmse: 0.925967\tvalid_1's rmse: 0.98867\n",
      "[400]\ttraining's rmse: 0.902043\tvalid_1's rmse: 0.983019\n",
      "[500]\ttraining's rmse: 0.882698\tvalid_1's rmse: 0.98027\n",
      "[600]\ttraining's rmse: 0.865488\tvalid_1's rmse: 0.97881\n",
      "[700]\ttraining's rmse: 0.850158\tvalid_1's rmse: 0.978053\n",
      "[800]\ttraining's rmse: 0.835538\tvalid_1's rmse: 0.977313\n",
      "[900]\ttraining's rmse: 0.821761\tvalid_1's rmse: 0.976981\n",
      "[1000]\ttraining's rmse: 0.808969\tvalid_1's rmse: 0.977182\n",
      "Early stopping, best iteration is:\n",
      "[930]\ttraining's rmse: 0.817767\tvalid_1's rmse: 0.976882\n",
      "Partial score of fold 2 is: 0.5957908683320088\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 1.02563\tvalid_1's rmse: 1.05584\n",
      "[200]\ttraining's rmse: 0.956518\tvalid_1's rmse: 1.01223\n",
      "[300]\ttraining's rmse: 0.92214\tvalid_1's rmse: 1.00018\n",
      "[400]\ttraining's rmse: 0.897813\tvalid_1's rmse: 0.995149\n",
      "[500]\ttraining's rmse: 0.878138\tvalid_1's rmse: 0.992914\n",
      "[600]\ttraining's rmse: 0.861123\tvalid_1's rmse: 0.992305\n",
      "[700]\ttraining's rmse: 0.845756\tvalid_1's rmse: 0.991948\n",
      "[800]\ttraining's rmse: 0.831213\tvalid_1's rmse: 0.991645\n",
      "Early stopping, best iteration is:\n",
      "[775]\ttraining's rmse: 0.834815\tvalid_1's rmse: 0.991553\n",
      "Partial score of fold 3 is: 0.5780482488254329\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 1.02967\tvalid_1's rmse: 1.04965\n",
      "[200]\ttraining's rmse: 0.960445\tvalid_1's rmse: 0.999803\n",
      "[300]\ttraining's rmse: 0.926779\tvalid_1's rmse: 0.984405\n",
      "[400]\ttraining's rmse: 0.902826\tvalid_1's rmse: 0.977908\n",
      "[500]\ttraining's rmse: 0.883195\tvalid_1's rmse: 0.975394\n",
      "[600]\ttraining's rmse: 0.866151\tvalid_1's rmse: 0.973727\n",
      "[700]\ttraining's rmse: 0.850449\tvalid_1's rmse: 0.972552\n",
      "[800]\ttraining's rmse: 0.835772\tvalid_1's rmse: 0.972125\n",
      "[900]\ttraining's rmse: 0.821916\tvalid_1's rmse: 0.972007\n",
      "[1000]\ttraining's rmse: 0.809105\tvalid_1's rmse: 0.97197\n",
      "[1100]\ttraining's rmse: 0.796864\tvalid_1's rmse: 0.971779\n",
      "[1200]\ttraining's rmse: 0.784988\tvalid_1's rmse: 0.971627\n",
      "Early stopping, best iteration is:\n",
      "[1126]\ttraining's rmse: 0.793754\tvalid_1's rmse: 0.971568\n",
      "Partial score of fold 4 is: 0.6074937987292433\n",
      "Our oof cohen kappa score is:  0.5982869559885218\n",
      "[0]\ttrain-rmse:1.8624\tval-rmse:1.86357\n",
      "Multiple eval metrics have been passed: 'val-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until val-rmse hasn't improved in 100 rounds.\n",
      "[100]\ttrain-rmse:0.994402\tval-rmse:1.15875\n",
      "[200]\ttrain-rmse:0.701022\tval-rmse:1.01617\n",
      "[300]\ttrain-rmse:0.588294\tval-rmse:0.993096\n",
      "[400]\ttrain-rmse:0.530968\tval-rmse:0.987545\n",
      "[500]\ttrain-rmse:0.499356\tval-rmse:0.986924\n",
      "[600]\ttrain-rmse:0.484904\tval-rmse:0.987289\n",
      "Stopping. Best iteration:\n",
      "[519]\ttrain-rmse:0.497043\tval-rmse:0.986877\n",
      "\n",
      "Partial score of fold 0 is: 0.5954500604527704\n",
      "[0]\ttrain-rmse:1.86238\tval-rmse:1.86356\n",
      "Multiple eval metrics have been passed: 'val-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until val-rmse hasn't improved in 100 rounds.\n",
      "[100]\ttrain-rmse:0.997277\tval-rmse:1.15686\n",
      "[200]\ttrain-rmse:0.707208\tval-rmse:1.0138\n",
      "[300]\ttrain-rmse:0.59096\tval-rmse:0.98929\n",
      "[400]\ttrain-rmse:0.536051\tval-rmse:0.985448\n",
      "[500]\ttrain-rmse:0.499523\tval-rmse:0.985119\n",
      "[600]\ttrain-rmse:0.4818\tval-rmse:0.984932\n",
      "[700]\ttrain-rmse:0.463652\tval-rmse:0.984933\n",
      "Stopping. Best iteration:\n",
      "[628]\ttrain-rmse:0.477837\tval-rmse:0.984878\n",
      "\n",
      "Partial score of fold 1 is: 0.5886945313938501\n",
      "[0]\ttrain-rmse:1.86231\tval-rmse:1.86353\n",
      "Multiple eval metrics have been passed: 'val-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until val-rmse hasn't improved in 100 rounds.\n",
      "[100]\ttrain-rmse:0.994692\tval-rmse:1.15996\n",
      "[200]\ttrain-rmse:0.701816\tval-rmse:1.02115\n",
      "[300]\ttrain-rmse:0.588488\tval-rmse:0.999921\n",
      "[400]\ttrain-rmse:0.52937\tval-rmse:0.996648\n",
      "[500]\ttrain-rmse:0.496456\tval-rmse:0.995638\n",
      "Stopping. Best iteration:\n",
      "[489]\ttrain-rmse:0.499691\tval-rmse:0.995566\n",
      "\n",
      "Partial score of fold 2 is: 0.5730480560553979\n",
      "[0]\ttrain-rmse:1.86248\tval-rmse:1.86373\n",
      "Multiple eval metrics have been passed: 'val-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until val-rmse hasn't improved in 100 rounds.\n",
      "[100]\ttrain-rmse:0.997361\tval-rmse:1.16555\n",
      "[200]\ttrain-rmse:0.704872\tval-rmse:1.02991\n",
      "[300]\ttrain-rmse:0.595681\tval-rmse:1.00976\n",
      "[400]\ttrain-rmse:0.542412\tval-rmse:1.00705\n",
      "[500]\ttrain-rmse:0.507942\tval-rmse:1.00749\n",
      "Stopping. Best iteration:\n",
      "[413]\ttrain-rmse:0.536594\tval-rmse:1.00694\n",
      "\n",
      "Partial score of fold 3 is: 0.5694995321540828\n",
      "[0]\ttrain-rmse:1.86228\tval-rmse:1.86375\n",
      "Multiple eval metrics have been passed: 'val-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until val-rmse hasn't improved in 100 rounds.\n",
      "[100]\ttrain-rmse:0.995655\tval-rmse:1.15445\n",
      "[200]\ttrain-rmse:0.704872\tval-rmse:1.01176\n",
      "[300]\ttrain-rmse:0.594238\tval-rmse:0.986204\n",
      "[400]\ttrain-rmse:0.545457\tval-rmse:0.982637\n",
      "[500]\ttrain-rmse:0.512307\tval-rmse:0.982304\n",
      "Stopping. Best iteration:\n",
      "[477]\ttrain-rmse:0.518045\tval-rmse:0.982213\n",
      "\n",
      "Partial score of fold 4 is: 0.5853875912989889\n",
      "Our oof cohen kappa score is:  0.5817048402945049\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#cat_model = Catb_Model(reduce_train, ajusted_test, features, categoricals=categoricals)\n",
    "lgb_model = Lgb_Model(reduce_train, ajusted_test, features, categoricals=categoricals)\n",
    "xgb_model = Xgb_Model(reduce_train, ajusted_test, features, categoricals=categoricals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cnn_model = Cnn_Model(reduce_train, ajusted_test, features, categoricals=categoricals)\n",
    "# nn_model = Nn_Model(reduce_train, ajusted_test, features, categoricals=categoricals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000,)\n"
     ]
    }
   ],
   "source": [
    "weights = {'lbg': 0.80, 'cat': 0, 'xgb': 0.20, 'nn': 0.00}\n",
    "\n",
    "final_pred = (lgb_model.y_pred * weights['lbg']) + (xgb_model.y_pred * weights['xgb']) \n",
    "#final_pred = cnn_model.y_pred\n",
    "print(final_pred.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pd.DataFrame([(round(a, 2), round(b, 2), round(c, 2), round(d, 2)) for a, b, c, d in zip(lgb_model.y_pred, cat_model.y_pred, xgb_model.y_pred, nn_model.y_pred)], columns=['lgb', 'cat', 'xgb', 'nn']).head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 1.3046261051644348, 1: 1.7377341826412769, 2: 1.9695713514421955}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3    0.504\n",
       "0    0.236\n",
       "1    0.136\n",
       "2    0.124\n",
       "Name: accuracy_group, dtype: float64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "dist = Counter(reduce_train['accuracy_group'])\n",
    "for k in dist:\n",
    "    dist[k] /= len(reduce_train)\n",
    "reduce_train['accuracy_group'].hist()\n",
    "\n",
    "acum = 0\n",
    "bound = {}\n",
    "for i in range(3):\n",
    "    acum += dist[i]\n",
    "    bound[i] = np.percentile(final_pred, acum * 100)\n",
    "print(bound)\n",
    "\n",
    "def classify(x):\n",
    "    if x <= bound[0]:\n",
    "        return 0\n",
    "    elif x <= bound[1]:\n",
    "        return 1\n",
    "    elif x <= bound[2]:\n",
    "        return 2\n",
    "    else:\n",
    "        return 3\n",
    "    \n",
    "final_pred = np.array(list(map(classify, final_pred)))\n",
    "\n",
    "sample_submission['accuracy_group'] = final_pred.astype(int)\n",
    "sample_submission.to_csv('submission.csv', index=False)\n",
    "sample_submission['accuracy_group'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "0f8fbc1dc7c946c5b2c627033dbd537d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "IntProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "IntProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "100%",
       "description_tooltip": null,
       "layout": "IPY_MODEL_3198b70da28047ef9f46b341c527ee6e",
       "max": 17000,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_bc2972de3dab4bbf9693277ce7f5b2d7",
       "value": 17000
      }
     },
     "11c7c10c6d694193bb68077b00357a23": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "23722272b7ff4922a8da6a5e520bc543": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": "initial"
      }
     },
     "270fc5c55e1d49d7906318182fce377d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_ef4a74da4e3e452f9f716b31cf528983",
       "placeholder": "​",
       "style": "IPY_MODEL_9f64d25818834d5090e6654c537b0c65",
       "value": " 17000/17000 [09:26&lt;00:00, 29.98it/s]"
      }
     },
     "3198b70da28047ef9f46b341c527ee6e": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "5e7dcfdc8e9543ea9df23d50d6ae7aa2": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_0f8fbc1dc7c946c5b2c627033dbd537d",
        "IPY_MODEL_270fc5c55e1d49d7906318182fce377d"
       ],
       "layout": "IPY_MODEL_d634caf07e7b4bfeb4da13eb04a83f50"
      }
     },
     "9f64d25818834d5090e6654c537b0c65": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "a28f70a7b3aa4507bc32bc4aeb042098": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "IntProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "IntProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "100%",
       "description_tooltip": null,
       "layout": "IPY_MODEL_ff5c2752c48044c184370523389cea67",
       "max": 1000,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_23722272b7ff4922a8da6a5e520bc543",
       "value": 1000
      }
     },
     "bc2972de3dab4bbf9693277ce7f5b2d7": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": "initial"
      }
     },
     "c251eb78a6c345dbaa7e4f7fa59f316c": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "ce79367993c94068bc4941095e5d9874": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_c251eb78a6c345dbaa7e4f7fa59f316c",
       "placeholder": "​",
       "style": "IPY_MODEL_f4344f8da6bc435cbe86cead5ef2c959",
       "value": " 1000/1000 [01:05&lt;00:00, 15.37it/s]"
      }
     },
     "d634caf07e7b4bfeb4da13eb04a83f50": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "ddeb594e1b324481b35383edca9c1858": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_a28f70a7b3aa4507bc32bc4aeb042098",
        "IPY_MODEL_ce79367993c94068bc4941095e5d9874"
       ],
       "layout": "IPY_MODEL_11c7c10c6d694193bb68077b00357a23"
      }
     },
     "ef4a74da4e3e452f9f716b31cf528983": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "f4344f8da6bc435cbe86cead5ef2c959": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "ff5c2752c48044c184370523389cea67": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
